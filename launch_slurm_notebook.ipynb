{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d80742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from textwrap import dedent\n",
    "from itertools import product\n",
    "import os\n",
    "CONDA_ENV_NAME = \"HL-env\"\n",
    "REPO_DIR = os.path.abspath(\".\")  # adjust if needed\n",
    "SWEEP_CONFIG = \"grid\"\n",
    "PROJECT = f\"decouple-alphas-{SWEEP_CONFIG}\"\n",
    "data = True # add the data param?\n",
    "slurm = False  # whether to launch the jobs on SLURM or not\n",
    "\n",
    "\n",
    "# Parameters that represent each unique optimisation space\n",
    "# You can also make an item a lambda function to evaluate it dynamically where the argument is the hyperparameter dictionary\n",
    "grid = {\n",
    "    \"default\": {\n",
    "        \"model\": [\"basic_mlp\"],\n",
    "        \"task\": [\"fmnist\"],\n",
    "        \"optimizer.lr\": [0.1, 0.5],\n",
    "        # \"optimizer.weight_decay\": [0.0, 1e-4, 1e-3],\n",
    "        # \"optimizer.momentum\": [0.0, 0.9, 0.99],\n",
    "        \"corruption.alpha\": [0.01, 0.25, 0.5, 0.75, 0.99],\n",
    "        \"trainer.min_epochs\": [\"20\"],\n",
    "        \"trainer.max_epochs\": [\"20\"],\n",
    "    },\n",
    "    \"md\": {\n",
    "        \"optimizer.update_alg\": ['md'],\n",
    "        \"optimizer.alpha\": [0.01, 0.25, 0.5, 0.75, 0.99],\n",
    "        \"optimizer.block_size\": ['4'],\n",
    "    },\n",
    "    # \"gd\": {\n",
    "    #     \"optimizer.update_alg\": ['gd'],\n",
    "    # },\n",
    "}\n",
    "\n",
    "def launch_job(**hp):\n",
    "    \"\"\"\n",
    "    Launch a job on SLURM with the specified parameters.\n",
    "\n",
    "    args == hyper params\n",
    "    \"\"\"\n",
    "    # if any value is a lambda function, evaluate it with the current hp\n",
    "    for key, value in hp.items():\n",
    "        if callable(value):\n",
    "            hp[key] = value(hp)\n",
    "\n",
    "    name = \"_\".join([str(hp[k]) for k in sorted(hp)])\n",
    "    study_name = f\"study_{name}\"\n",
    "    group = name\n",
    "\n",
    "    data_dir = \"$TMP_SHARED\"\n",
    "    # Create the batch script as a multi-line string\n",
    "    template_script = dedent(f\"\"\"\\\n",
    "        #!/bin/bash\n",
    "        #SBATCH --job-name={name}\n",
    "        #SBATCH --output=slurm-logs/{PROJECT}/{name}_%j.out\n",
    "        #SBATCH --error=slurm-logs/{PROJECT}/{name}_%j.err\n",
    "        #SBATCH --time=01:00:00\n",
    "        #SBATCH --partition=gpu\n",
    "        #SBATCH --gres=gpu:1\n",
    "        #SBATCH --mem=16G\n",
    "        #SBATCH --cpus-per-task=4\n",
    "\n",
    "        module load miniforge\n",
    "        conda activate $HOME/{CONDA_ENV_NAME}\n",
    "\n",
    "        export CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "\n",
    "        LOGGING=\"$SCRATCH/{PROJECT}/{study_name}\"\n",
    "\n",
    "        mkdir -p \"$LOGGING\"\n",
    "        CHKP=\"$LOGGING/last.ckpt\"\n",
    "\n",
    "        cd $LOGGING\n",
    "        echo \"Copying data from {REPO_DIR}/data into {data_dir}/data\"\n",
    "        cp -r \"{REPO_DIR}/data\" \"{data_dir}/data\"\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "    cmd = [\n",
    "        \"python\", f\"{REPO_DIR}/src/train.py\", \"-m\", \n",
    "        f\"hydra.sweeper.study_name={study_name}\",\n",
    "        f\"hparams_search={SWEEP_CONFIG}\",\n",
    "        f\"logger.group={group}\",\n",
    "        f\"save_dir=$LOGGING\" if slurm else f\"save_dir={REPO_DIR}/logs/{PROJECT}/{study_name}\",\n",
    "        f\"logger.project={PROJECT}\",\n",
    "    ]\n",
    "\n",
    "    if data:\n",
    "        cmd.append(f\"data.data_dir={data_dir}/data\")\n",
    "\n",
    "\n",
    "    # the keu is the name of the hyperparameter, the value is the value to set it to\n",
    "    for key, value in hp.items():\n",
    "        cmd.append(f\"{key}={value}\")\n",
    "\n",
    "    # Add the command to run the script\n",
    "    batch_script = template_script + \"\\n\" + \" \".join(cmd) + \"\\n\" + \"echo 'Job completed.'\\n\"\n",
    "\n",
    "    # Write the script to a temp file (can be named uniquely)\n",
    "    script_filename = f\"tmp.sh\"\n",
    "\n",
    "    if slurm:\n",
    "        with open(script_filename, \"w\") as f:\n",
    "            f.write(batch_script)\n",
    "\n",
    "        # Launch the job using sbatch\n",
    "        subprocess.run([\"sbatch\", script_filename])\n",
    "    else:\n",
    "        # If not using SLURM, just run the command directly\n",
    "        print(\"Running command directly (not on SLURM):\", \" \".join(cmd))\n",
    "        subprocess.run(cmd)\n",
    "\n",
    "def print_grid_stats(grid):\n",
    "    default = grid.get(\"default\", {})\n",
    "    total = 0\n",
    "\n",
    "    print(\"Grid Search Stats:\\n\")\n",
    "\n",
    "    for space, params in grid.items():\n",
    "        if space == \"default\":\n",
    "            continue\n",
    "\n",
    "        # Merge default with specific subspace params\n",
    "        full_params = {**default, **params}\n",
    "        keys = sorted(full_params.keys())\n",
    "        values_list = [full_params[key] for key in keys]\n",
    "\n",
    "        num_configs = 1\n",
    "        for v in values_list:\n",
    "            num_configs *= len(v)\n",
    "\n",
    "        print(f\"  - {space}: {num_configs} configurations\")\n",
    "        total += num_configs\n",
    "\n",
    "    print(f\"\\nTotal configurations: {total}\")\n",
    "\n",
    "\n",
    "print_grid_stats(grid)\n",
    "input(\"Press Enter to continue... or Ctrl+C to exit.\")\n",
    "for space, params in grid.items():\n",
    "    if space == \"default\":\n",
    "        continue\n",
    "\n",
    "    # Add the default parameters to the grid\n",
    "    full_params = {**grid[\"default\"], **params}\n",
    "    keys = sorted(full_params.keys())\n",
    "    values_list = [full_params[key] for key in keys]\n",
    "\n",
    "    for values in product(*values_list):\n",
    "        hp = {\n",
    "            key: value\n",
    "            for key, value in zip(keys, values)\n",
    "        }\n",
    "        # Launch the job with the hyperparameters\n",
    "        launch_job(**hp)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
